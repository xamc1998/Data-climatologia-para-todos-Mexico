{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este proyecto tiene como objetivo estructurar una base de datos con información climática histórica proveniente de las estaciones de monitoreo de CONAGUA distribuidas en la República Mexicana.\n",
    "\n",
    "Durante el desarrollo, identificamos dos retos técnicos principales:\n",
    "\n",
    "- Estructuras DOM complejas y dinámicas: El sitio utiliza capas de diseño que impiden un web scraping convencional basado en peticiones estáticas.\n",
    "\n",
    "- Acceso a datos históricos: La información de archivo no reside directamente en la interfaz, sino que se gestiona a través de redirecciones a archivos planos (.txt).\n",
    "\n",
    "¿Suena complejo? Definitivamente lo fue. Para concretar este proyecto, fue necesario realizar un análisis de ingeniería inversa sobre la carga de etiquetas, automatizar la interacción con elementos dinámicos y diseñar una arquitectura de extracción que respete la integridad del sitio web fuente.\n",
    "\n",
    "Este notebook documenta el proceso completo para ejecutar un web scraping masivo de manera eficiente.\n",
    "\n",
    "Nota sobre el alcance: Aunque el sistema de CONAGUA ofrece múltiples variables, este proyecto se enfoca específicamente en la extracción de precipitaciones y temperaturas. Te invito a explorar el sitio fuente, donde cada marcador (\"pin\") contiene un catálogo aún más amplio de datos.\n",
    "\n",
    "Ética y Responsabilidad\n",
    "La ética en el scraping es innegociable. Para evitar la saturación de los servidores de CONAGUA, hemos implementado técnicas de navegación conservadoras, incluyendo intervalos de espera (time.sleep) calculados a conciencia.\n",
    "\n",
    "Nota: Por razones de seguridad y buenas prácticas, ciertos segmentos sensibles del código (como endpoints específicos o credenciales) han sido omitidos o anonimizados.\n",
    "\n",
    "Consideraciones adicionales:\n",
    "- Deben de tener en cuenta que en ocasiones algunos censores no podran ser alcanzados. Para lidiar con esto se sugiere tener un manejo de errores que documente que censores atraves de su id no pudieron ser analizados, de esta manera mantienes una extraccion resiliente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36913,
     "status": "ok",
     "timestamp": 1759522617467,
     "user": {
      "displayName": "Xavier Aaron Melendrez Cruz",
      "userId": "15789268252139956638"
     },
     "user_tz": 360
    },
    "id": "sPkNW1mjt80u",
    "outputId": "ba453ca5-e03b-4bab-9f83-187eb10d5bc7"
   },
   "outputs": [],
   "source": [
    "%pip install requests pandas selenium\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "# --- Librerías de Selenium (Completas y Ordenadas para entorno local) ---\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "# Importaciones específicas para Chrome (mejor compatibilidad con versiones recientes)\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "executionInfo": {
     "elapsed": 8610,
     "status": "ok",
     "timestamp": 1759522080222,
     "user": {
      "displayName": "Xavier Aaron Melendrez Cruz",
      "userId": "15789268252139956638"
     },
     "user_tz": 360
    },
    "id": "mI3qDRAsz5cg",
    "outputId": "f0b134c0-8df8-4078-fb3f-bbe0a28c6694"
   },
   "outputs": [],
   "source": [
    "## Ejecucion de pruebas 200 para acreditar el acceso a los links.\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "# import csv # Ya no es necesario\n",
    "# import os  # Ya no es necesario\n",
    "import pandas as pd\n",
    "\n",
    "# Definir directamente la URL a probar\n",
    "urls = [\"https://smn.conagua.gob.mx/tools/GUI/ENCS.php?logo=0\"]\n",
    "\n",
    "resultados = []\n",
    "\n",
    "print(\"Iniciando prueba de conexión...\")\n",
    "\n",
    "# Iterar sobre las URLs y probar cada una. En este caso estamos probando una sola URL.\n",
    "for i, url in enumerate(urls):\n",
    "    print(f\"Probando link número {i+1} de {len(urls)}: {url}\")\n",
    "    try:\n",
    "        user_agents = [\n",
    "    \"\"\" \n",
    "    Es necesario la inclusion de webdrivers para emular un entorno en mozila firefox o google chrome\n",
    "    Se recomienda Mozila\n",
    "    \"\"\",\n",
    "        ]\n",
    "        headers = {'User-Agent': random.choice(user_agents)}\n",
    "\n",
    "        # Realiza la solicitud\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "\n",
    "        # Levanta un error para códigos 4xx/5xx\n",
    "        response.raise_for_status()\n",
    "\n",
    "        codigo_estado = response.status_code\n",
    "        error = \"\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Intenta obtener el código si la respuesta existe, si no, usa un mensaje genérico.\n",
    "        codigo_estado = f\"Error {response.status_code}\" if 'response' in locals() and response is not None and response.status_code is not None else \"Error de Conexión\"\n",
    "        error = str(e)\n",
    "        print(f\"Error con {url}: {e}\")\n",
    "    except Exception as e:\n",
    "        # Captura cualquier otro error inesperado\n",
    "        codigo_estado = \"Error Inesperado\"\n",
    "        error = str(e)\n",
    "        print(f\"Error inesperado con {url}: {e}\")\n",
    "    finally:\n",
    "        # Registra el resultado en la lista\n",
    "        resultados.append([i+1, url, codigo_estado, error])\n",
    "\n",
    "    time.sleep(random.uniform(5, 10))\n",
    "\n",
    "print(\"\\n--- Pruebas completadas ---\")\n",
    "\n",
    "# Crear DataFrame y visualizarlo\n",
    "columnas = [\"Número de Link\", \"URL\", \"Código de Estado\", \"Error\"]\n",
    "df_resultados = pd.DataFrame(resultados, columns=columnas)\n",
    "\n",
    "df_resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El codigo 200 acredita exitosamente nuestra solicitud de conexion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodología de Extracción Dinámica\n",
    "Para evitar procesos redundantes y consolidar la navegación de Selenium, se diseñó una estrategia de interacción que garantiza el acceso a los elementos del DOM dinámico. Dado que la información climática solo se genera tras eventos específicos del usuario, el código implementa un flujo de trabajo basado en cuatro pilares:\n",
    "\n",
    "1. Preparación del Entorno (Setup de Interfaz)\n",
    "- Antes de buscar un sensor específico, el script automatiza la configuración del mapa para asegurar que la información sea \"clicable\":\n",
    "\n",
    "- Gestión de Capas: Se activan tanto las estaciones \"operando\" como las \"suspendidas\" mediante selectores CSS, garantizando que el universo de datos sea completo.\n",
    "\n",
    "- Ajuste de Visibilidad: Se implementa un control de Zoom In y el cierre de paneles laterales para maximizar el área de interacción y evitar errores de superposición de elementos (MoveTargetOutOfBoundsException).\n",
    "\n",
    "2. Orquestación de Eventos Complejos (ActionChains)\n",
    "- La información objetivo no reside de forma estática en el HTML. Para extraerla, el script imita el comportamiento humano avanzado:\n",
    "\n",
    "- Doble Clic Estratégico: Se utiliza la clase ActionChains para ejecutar un doble clic sobre el marcador del sensor. Este evento es el disparador necesario para que el sitio despliegue y \"ancle\" el contenedor de información (popover-content).\n",
    "\n",
    "- Limpieza de Estado: Tras cada extracción, el script realiza un clic en una zona neutra del mapa para cerrar ventanas emergentes y preparar la interfaz para la siguiente búsqueda.\n",
    "\n",
    "3. Sincronización y Esperas Inteligentes\n",
    "- Para mitigar la latencia del sitio y no saturar sus servidores, se emplean dos tipos de control temporal:\n",
    "\n",
    "- Esperas Explícitas (WebDriverWait): El código espera hasta 45 segundos a que elementos cruciales aparezcan, permitiendo que el script sea resiliente a conexiones lentas.\n",
    "\n",
    "- Intervalos de Estabilidad (time.sleep): Pausas estratégicas de 1 a 3 segundos que dan margen a las animaciones de la interfaz y previenen bloqueos por comportamiento automatizado agresivo.\n",
    "\n",
    "4. Extracción y Limpieza con RegEx\n",
    "- Una vez que el contenido dinámico es visible, se recupera el atributo innerHTML. Dado que los datos vienen en bloques de texto mezclados con etiquetas HTML, se utiliza Expresiones Regulares (RegEx) para parsear con precisión:\n",
    "\n",
    "- Nombre de la estación.\n",
    "\n",
    "- Coordenadas geográficas (Latitud y Longitud).\n",
    "\n",
    "- URLs directas a los archivos históricos (.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pruebas preeliminares exitosas\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException, StaleElementReferenceException, MoveTargetOutOfBoundsException\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "from selenium.webdriver.common.action_chains import ActionChains \n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions \n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import re \n",
    "from pprint import pprint \n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# --- PARTE 1: CONFIGURACIÓN Y SELECTORES ---\n",
    "# -------------------------------------------------------------------\n",
    "URL_BASE = \"https://smn.conagua.gob.mx\"\n",
    "URL_CONAGUA = f\"{URL_BASE}/tools/GUI/ENCS.php?logo=0\"\n",
    "WAIT_TIME = 45 # Espera máxima para elementos cruciales\n",
    "\n",
    "ID_A_PROCESAR = [\"1001\"] \n",
    "\n",
    "# Selectores CSS/XPath\n",
    "####\n",
    "\n",
    "# XPaths Robustos: Buscan los enlaces por el texto que contienen\n",
    "###\n",
    "\n",
    "resultados_finales = []\n",
    "driver = None\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# --- FUNCIÓN DE EXTRACCIÓN POR SENSOR (DOBLE CLIC IMPLEMENTADO) ---\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def extraer_datos_sensor(id_sensor, driver):\n",
    "    \"\"\"Realiza la búsqueda, el evento de doble clic y extrae los datos de un sensor.\"\"\"\n",
    "    #Datos a extaer\n",
    "    datos_sensor = {\n",
    "        'Nombre': str(id_sensor), \n",
    "        'Nombre': None,\n",
    "        'Latitud': None,\n",
    "        'Longitud': None,\n",
    "        'URL_Diaria': None,\n",
    "        'URL_Mensual': None,\n",
    "        'Estado': 'FALLO'\n",
    "    }\n",
    "    \n",
    "    # ----------------------- FASE DE BÚSQUEDA -----------------------\n",
    "    try:\n",
    "        CADENA_DE_BUSQUEDA = f\"- {id_sensor}\"\n",
    "        print(f\"\\n[PROCESANDO] ID: {id_sensor} | Búsqueda: {CADENA_DE_BUSQUEDA}\")\n",
    "        \n",
    "        search_box = WebDriverWait(driver, WAIT_TIME).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, css_selector_search_box))\n",
    "        )\n",
    "        \n",
    "        search_box.clear() \n",
    "        search_box.send_keys(CADENA_DE_BUSQUEDA)\n",
    "        time.sleep(1.5) \n",
    "        search_box.send_keys(Keys.ENTER)\n",
    "        time.sleep(3) \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" [ERROR] Fallo en la búsqueda del sensor {id_sensor}. Error: {type(e).__name__}. Saltando.\")\n",
    "        return datos_sensor\n",
    "\n",
    "    # ----------------------- FASE DE DOBLE CLIC PARA DESPLEGAR CONTENIDO -----------------------\n",
    "    try:\n",
    "        # Esperar a que el pop-up ancla sea visible para el usuario (prevención de MoveTargetOutOfBoundsException)\n",
    "        popup_ancla = WebDriverWait(driver, WAIT_TIME).until(\n",
    "            EC.visibility_of_element_located((By.CSS_SELECTOR, css_selector_popup_ancla))\n",
    "        )\n",
    "        \n",
    "        # Pausa extra para estabilidad\n",
    "        time.sleep(1) \n",
    "        \n",
    "        # NUEVA ACCIÓN CLAVE: Simular el doble clic \n",
    "        print(\" [DOBLE CLIC ACTIONCHAINS] Ejecutando doble_click en div#popup para desplegar y anclar contenido...\")\n",
    "        ActionChains(driver).double_click(popup_ancla).perform()\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Esperar a que el contenedor principal del pop-up esté visible después del doble clic\n",
    "        popover_content = WebDriverWait(driver, WAIT_TIME).until(\n",
    "            EC.visibility_of_element_located((By.CSS_SELECTOR, css_selector_popover_content))\n",
    "        )\n",
    "        print(\" [DIAGNÓSTICO] Contenedor popover-content es visible. Iniciando extracción...\")\n",
    "        \n",
    "    except MoveTargetOutOfBoundsException as e:\n",
    "        print(f\" [ERROR] MoveTargetOutOfBoundsException: El ancla del pop-up no estaba en la pantalla/interactuable. Detalles: {e.msg.splitlines()[0]}\")\n",
    "        return datos_sensor\n",
    "    except Exception as e:\n",
    "        print(f\" [ERROR] Fallo al hacer doble clic o al encontrar el contenedor popover-content. Error: {type(e).__name__} - {e}\")\n",
    "        return datos_sensor\n",
    "\n",
    "    # ----------------------- FASE DE EXTRACCIÓN DE DATOS -----------------------\n",
    "    \n",
    "    # 1. Recuperar la celda con datos generales (TD)\n",
    "    try:\n",
    "        print(f\" [SINCRONIZACIÓN] Esperando {WAIT_TIME} segundos por el contenido de la tabla...\")\n",
    "        datos_generales_td = WebDriverWait(driver, WAIT_TIME).until(\n",
    "             EC.presence_of_element_located((By.CSS_SELECTOR, css_selector_data_td))\n",
    "        )\n",
    "        datos_texto = datos_generales_td.get_attribute('innerHTML')\n",
    "        print(\" [EXTRACCIÓN] OK: Celda de datos generales (TD) encontrada.\")\n",
    "    except TimeoutException:\n",
    "        print(f\" [ERROR 1.1] TIMEOUT: La celda de datos no apareció después de {WAIT_TIME} segundos. La carga es demasiado lenta.\")\n",
    "        return datos_sensor\n",
    "    except Exception as e:\n",
    "        print(f\" [ERROR 1.1] EXCEPCIÓN: Fallo al encontrar la CELDA de datos generales. Tipo: {type(e).__name__}. Detalles: {e}\")\n",
    "        return datos_sensor\n",
    "\n",
    "    # 2. Extracción de URLs (Diaria y Mensual)\n",
    "    try:\n",
    "        popover_content_fresh = driver.find_element(By.CSS_SELECTOR, css_selector_popover_content)\n",
    "\n",
    "        enlace_diaria = popover_content_fresh.find_element(By.XPATH, xpath_diaria)\n",
    "        enlace_mensual = popover_content_fresh.find_element(By.XPATH, xpath_mensual)\n",
    "\n",
    "        # Usamos directamente el valor del href (CORRECCIÓN PREVIA para evitar duplicidad de URL)\n",
    "        datos_sensor['URL_Diaria'] = enlace_diaria.get_attribute(\"href\")\n",
    "        datos_sensor['URL_Mensual'] = enlace_mensual.get_attribute(\"href\")\n",
    "        \n",
    "        print(\" [EXTRACCIÓN] OK: Enlaces 'Diaria' y 'Mensual' encontrados y capturados.\")\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        print(f\" [ERROR 1.2] NoSuchElementException: Uno o ambos enlaces (Diaria/Mensual) no fueron encontrados dentro del popover activo.\")\n",
    "        return datos_sensor\n",
    "    except Exception as e:\n",
    "        print(f\" [ERROR 1.2] EXCEPCIÓN: Fallo al encontrar los enlaces. Tipo: {type(e).__name__}. Detalles: {e}\")\n",
    "        return datos_sensor\n",
    "\n",
    "    # 3. Extracción de datos con RegEx\n",
    "    try:\n",
    "        nombre_match = re.search(r'<b>Nombre: </b>(.*?)<br>', datos_texto)\n",
    "        latitud_match = re.search(r'<b>Latitud: </b>(.*?)º', datos_texto)\n",
    "        longitud_match = re.search(r'<b>Longitud: </b>(.*?)º', datos_texto)\n",
    "        \n",
    "        if nombre_match:\n",
    "            datos_sensor['Nombre'] = nombre_match.group(1).strip()\n",
    "        if latitud_match:\n",
    "            datos_sensor['Latitud'] = latitud_match.group(1).strip()\n",
    "        if longitud_match:\n",
    "            datos_sensor['Longitud'] = longitud_match.group(1).strip()\n",
    "        \n",
    "        datos_sensor['Estado'] = 'EXITO'\n",
    "        print(\" [EXTRACCIÓN] OK: Datos de RegEx procesados con éxito.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" [ERROR 1.3] EXCEPCIÓN: Fallo en el procesamiento RegEx. Tipo: {type(e).__name__}. Detalles: {e}\")\n",
    "        datos_sensor['Estado'] = 'FALLO (RegEx)'\n",
    "        \n",
    "    return datos_sensor\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# --- PARTE 2: PRUEBA DE EJECUCIÓN ---\n",
    "# -------------------------------------------------------------------\n",
    "try:\n",
    "    # 2.1 Inicialización del driver\n",
    "    print(\" [INICIO] Intentando inicializar Mozilla Firefox (GeckoDriver)...\")\n",
    "    driver = webdriver.Firefox() \n",
    "    driver.get(URL_CONAGUA)\n",
    "    \n",
    "    # 2.2 Configuración inicial (Pasos 1, 2 y 3)\n",
    "    arrow_icon = WebDriverWait(driver, WAIT_TIME).until(EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector_arrow)))\n",
    "    arrow_icon.click()\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "    for selector in [css_selector_checkbox_operando, css_selector_checkbox_suspendida]:\n",
    "        checkbox = WebDriverWait(driver, WAIT_TIME).until(EC.element_to_be_clickable((By.CSS_SELECTOR, selector)))\n",
    "        if not checkbox.is_selected(): checkbox.click() \n",
    "    time.sleep(1) \n",
    "    \n",
    "    # Zoom In \n",
    "    print(f\"\\n[PASO 5.1] Dando doble clic de Zoom In...\")\n",
    "    zoom_in_button = WebDriverWait(driver, WAIT_TIME).until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector_zoom_in))\n",
    "    )\n",
    "    # Doble clic para asegurar un buen nivel de zoom \n",
    "    zoom_in_button.click()\n",
    "    time.sleep(1) \n",
    "    zoom_in_button.click() # Segundo clic para zoom adicional\n",
    "    time.sleep(1)\n",
    "    \n",
    "    # 2.3 Cerrar Panel (Paso 5.2)\n",
    "    close_button = WebDriverWait(driver, WAIT_TIME).until(EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector_close_panel)))\n",
    "    close_button.click()\n",
    "    time.sleep(1)\n",
    "\n",
    "    # 2.4 Bucle de prueba (solo ID 1001)\n",
    "    print(\"\\n--- INICIANDO PRUEBA CON SENSOR 1001 ---\")\n",
    "    for id_sensor in ID_A_PROCESAR:\n",
    "        datos = extraer_datos_sensor(id_sensor, driver)\n",
    "        resultados_finales.append(datos)\n",
    "        \n",
    "        # Clic simple en el mapa para cerrar el pop-up y limpiar para la próxima búsqueda\n",
    "        map_element = driver.find_element(By.ID, \"map\") \n",
    "        ActionChains(driver).move_to_element(map_element).click().perform()\n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "finally:\n",
    "    # -------------------------------------------------------------------\n",
    "    # --- RESULTADOS DE LA PRUEBA ---\n",
    "    # -------------------------------------------------------------------\n",
    "    print(\"\\n==============================================\")\n",
    "    print(\"  RESULTADO DE LA PRUEBA (SENSOR 1001)  \")\n",
    "    print(\"==============================================\")\n",
    "    \n",
    "    if resultados_finales:\n",
    "        df_prueba = pd.DataFrame(resultados_finales)\n",
    "        print(df_prueba.to_string(index=False)) \n",
    "    else:\n",
    "        print(\"La extracción para el sensor 1001 falló.\") #manejo de errores, muy importante\n",
    "        \n",
    "    if driver:\n",
    "        print(\"\\nPrueba finalizada. Cierra el navegador manualmente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pueden encontrar estos csv en el sitio de CONAGUA afiliado al visual sobre el cual se está trabajando. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Csv de las bases de datos\n",
    "\n",
    "operativos = pd.read_csv(r'direccion_x....\\operativas.csv')\n",
    "suspendidos = pd.read_csv(r'direccion_x....\\suspendidas.csv')\n",
    "operativos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación del Procesamiento Masivo y Consolidación de Datos\n",
    "Tras validar la técnica de interacción dinámica, el siguiente paso consiste en escalar la extracción a nivel nacional. Esta sección del código implementa una arquitectura de procesamiento por lotes (batch processing) que integra fuentes de datos externas y mecanismos de persistencia para consolidar la base de datos climática.\n",
    "\n",
    "La estrategia se divide en tres componentes clave:\n",
    "\n",
    "1. Ingesta y Unificación de Catálogos\n",
    "El proceso comienza fuera del navegador. El script utiliza la librería pandas para leer catálogos locales de estaciones:\n",
    "\n",
    "- Fusión de Estructuras: Se cargan y unifican los listados de estaciones operativas y suspendidas.\n",
    "\n",
    "- Normalización de IDs: Se extraen y limpian los identificadores únicos (columna Name), eliminando duplicados mediante estructuras de conjuntos (set) para asegurar que cada torre climatológica se procese exactamente una vez.\n",
    "\n",
    "2. Ciclo de Extracción de Alto Rendimiento\n",
    "Para procesar cientos de estaciones de forma consecutiva sin que el script colapse, se refinó la función de extracción con controles de estado:\n",
    "\n",
    "- Sincronización de Contenido Crítico: A diferencia de una carga web normal, aquí el script espera a que el enlace interno \"Climatología diaria\" sea detectable en el DOM antes de proceder. Esto actúa como un ancla de seguridad que confirma que el pop-up no está vacío.\n",
    "\n",
    "- Recuperación Automática de Errores: Cada sensor se envuelve en bloques try-except. Si una estación falla (por carga lenta o error de red), el script registra el estado de FALLO, limpia la interfaz y continúa con la siguiente, evitando la interrupción total del proceso masivo.\n",
    "\n",
    "3. Persistencia y Auditoría de Resultados\n",
    "- El objetivo final es transformar la interacción visual en datos estructurados listos para el análisis:\n",
    "\n",
    "- Extracción Multivariable: Se capturan simultáneamente metadatos geográficos (Latitud/Longitud) y los puntos de acceso (URLs) a los archivos .txt históricos.\n",
    "\n",
    "- Exportación Robusta: Al finalizar el bucle, los resultados se consolidan en un DataFrame maestro que se exporta a un archivo CSV mediante rutas de cadena cruda (raw strings) para garantizar la compatibilidad con el sistema de archivos de Windows.\n",
    "\n",
    "- Resumen de Operación: El sistema genera un reporte automático de estados (Value Counts) que permite auditar cuántas estaciones fueron procesadas con éxito y cuántas requieren una revisión manual.\n",
    "\n",
    "- Seguridad de la Información: Se han implementado rutas de acceso y selectores protegidos para cumplir con las mejores prácticas de seguridad, asegurando que el flujo lógico sea reproducible sin exponer información sensible del entorno local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraccion de los archivos .txt de las torres climatologicas al nivel nacional \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException, StaleElementReferenceException, MoveTargetOutOfBoundsException\n",
    "from selenium.webdriver.common.keys import Keys \n",
    "from selenium.webdriver.common.action_chains import ActionChains \n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions \n",
    "\n",
    "import time\n",
    "import sys\n",
    "import pandas as pd\n",
    "import re \n",
    "from pprint import pprint \n",
    "import os \n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# --- PARTE 1: CONFIGURACIÓN Y DATOS DE ENTRADA (CARGA MEJORADA) ---\n",
    "# -------------------------------------------------------------------\n",
    "URL_BASE = \"https://smn.conagua.gob.mx\"\n",
    "URL_CONAGUA = f\"{URL_BASE}/tools/GUI/ENCS.php?logo=0\"\n",
    "WAIT_TIME = 45 # Espera máxima para elementos cruciales\n",
    "\n",
    "# Lectura directa de archivos CSV (Tu implementación, asegurando la ruta 'raw' con 'r')\n",
    "try:\n",
    "    operativos = pd.read_csv(r'direccion_x....\\operativas.csv')\n",
    "    suspendidos = pd.read_csv(r'direccion_x....\\suspendidas.csv')\n",
    "\n",
    "    # CORRECCIÓN CRÍTICA 1: Usar 'r' (raw string) para la ruta de salida para evitar errores de escape.\n",
    "    ARCHIVO_SALIDA = r\"direccion_x...\\Resultados_conagua.csv\"\n",
    "    \n",
    "    # Asignamos los DataFrames para usarlos en la función de carga (adaptación)\n",
    "    ARCHIVO_OPERATIVAS_DF = operativos\n",
    "    ARCHIVO_SUSPENDIDAS_DF = suspendidos\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n[ERROR FATAL] Uno o ambos archivos CSV no se encontraron. Revise la ruta.\")\n",
    "    print(f\"Detalle del error: {e}\")\n",
    "    sys.exit()\n",
    "except Exception as e:\n",
    "    print(f\"\\n[ERROR FATAL] Ocurrió un error al leer los archivos CSV: {e}\")\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# Selectores CSS/XPath (Se mantienen sin cambios)\n",
    "# selectores censurados\n",
    "\n",
    "# XPaths Robustos (Se mantienen sin cambios)\n",
    "# XPaths censurados\n",
    "\n",
    "resultados_finales = []\n",
    "driver = None\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# --- FUNCIÓN DE CARGA Y PREPARACIÓN DE DATOS (COLUMNA 'Name' CORREGIDA) ---\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def cargar_ids_a_procesar(df_operativas, df_suspendidas):\n",
    "    \"\"\"Extrae y combina los IDs únicos de las estaciones desde los DataFrames usando la columna 'Name'.\"\"\"\n",
    "    \n",
    "    print(\"[CARGA DATOS] Extrayendo IDs de los DataFrames cargados (usando columna 'Name')...\")\n",
    "\n",
    "    try:\n",
    "\n",
    "        ids_operativas = df_operativas['Name'].dropna().astype(str).tolist()\n",
    "        print(f\" [OK] {len(ids_operativas)} IDs Operativas cargadas.\")\n",
    "        \n",
    "\n",
    "        ids_suspendidas = df_suspendidas['Name'].dropna().astype(str).tolist()\n",
    "        print(f\" [OK] {len(ids_suspendidas)} IDs Suspendidas cargadas.\")\n",
    "        \n",
    "    except KeyError as e:\n",
    "        print(f\" [ERROR] Error: El DataFrame no contiene una columna llamada 'Name'. Revise el archivo CSV. Detalle: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\" [ERROR] Fallo al procesar los IDs. Error: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Combinar y retornar\n",
    "    ids_combinados = list(set(ids_operativas + ids_suspendidas))\n",
    "    print(f\" [RESUMEN] Total de IDs únicos a procesar: {len(ids_combinados)}\")\n",
    "    \n",
    "    return ids_combinados\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# --- FUNCIÓN DE EXTRACCIÓN POR SENSOR  ---\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def extraer_datos_sensor(id_sensor, driver):\n",
    "    \"\"\"Realiza la búsqueda, el evento de doble clic y extrae los datos de un sensor.\"\"\"\n",
    "    \n",
    "    #Datos a extaer\n",
    "    datos_sensor = {\n",
    "        'Clave': str(id_sensor), \n",
    "        'Nombre': None,\n",
    "        'Latitud': None,\n",
    "        'Longitud': None,\n",
    "        'URL_Diaria': None,\n",
    "        'URL_Mensual': None,\n",
    "        'Estado': 'FALLO'\n",
    "    }\n",
    "    \n",
    "    # ----------------------- FASE DE BÚSQUEDA -----------------------\n",
    "    try:\n",
    "        # La búsqueda utiliza el ID (que ahora es el valor de la columna 'Name')\n",
    "        CADENA_DE_BUSQUEDA = f\"- {id_sensor}\" \n",
    "        print(f\"\\n[PROCESANDO] ID: {id_sensor} | Búsqueda: {CADENA_DE_BUSQUEDA}\")\n",
    "        \n",
    "        search_box = WebDriverWait(driver, WAIT_TIME).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, css_selector_search_box))\n",
    "        )\n",
    "        \n",
    "        search_box.clear() \n",
    "        search_box.send_keys(CADENA_DE_BUSQUEDA)\n",
    "        time.sleep(1.5) \n",
    "        search_box.send_keys(Keys.ENTER)\n",
    "        time.sleep(3) \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" [ERROR] Fallo en la búsqueda del sensor {id_sensor}. Error: {type(e).__name__}.\")\n",
    "        return datos_sensor\n",
    "\n",
    "    # ----------------------- FASE DE DOBLE CLIC PARA DESPLEGAR CONTENIDO -----------------------\n",
    "    try:\n",
    "        popup_ancla = WebDriverWait(driver, WAIT_TIME).until(\n",
    "            EC.visibility_of_element_located((By.CSS_SELECTOR, css_selector_popup_ancla))\n",
    "        )\n",
    "        \n",
    "        time.sleep(1) \n",
    "        \n",
    "        print(\" [DOBLE CLIC ACTIONCHAINS] Ejecutando doble_click...\")\n",
    "        ActionChains(driver).double_click(popup_ancla).perform()\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Espera que el contenedor principal del pop-up sea visible\n",
    "        popover_content = WebDriverWait(driver, WAIT_TIME).until(\n",
    "            EC.visibility_of_element_located((By.CSS_SELECTOR, css_selector_popover_content))\n",
    "        )\n",
    "        print(\" [DIAGNÓSTICO] Contenedor popover-content visible.\")\n",
    "        \n",
    "    except MoveTargetOutOfBoundsException as e:\n",
    "        print(f\" [ERROR] MoveTargetOutOfBoundsException: El pop-up no estaba en la pantalla/interactuable.\")\n",
    "        return datos_sensor\n",
    "    except Exception as e:\n",
    "        print(f\" [ERROR] Fallo al hacer doble clic o al encontrar el popover. Error: {type(e).__name__}.\")\n",
    "        return datos_sensor\n",
    "\n",
    "    # ----------------------- FASE DE EXTRACCIÓN DE DATOS -----------------------\n",
    "    \n",
    "    # CORRECCIÓN DE ESTABILIDAD: Esperar explícitamente por el enlace interno.\n",
    "    try:\n",
    "        print(\" [SINCRONIZACIÓN] Esperando a que el enlace 'Climatología diaria' esté presente...\")\n",
    "        enlace_diaria = WebDriverWait(popover_content, WAIT_TIME).until(\n",
    "            EC.presence_of_element_located((By.XPATH, xpath_diaria))\n",
    "        )\n",
    "        print(\" [EXTRACCIÓN] OK: Enlace 'Diaria' encontrado. El pop-up está cargado.\")\n",
    "        \n",
    "        # 1. Recuperar la celda con datos generales (TD)\n",
    "        datos_generales_td = driver.find_element(By.CSS_SELECTOR, css_selector_data_td)\n",
    "        datos_texto = datos_generales_td.get_attribute('innerHTML')\n",
    "\n",
    "        # 2. Extracción de URLs (Mensual)\n",
    "        # Reutilizamos el 'enlace_diaria' encontrado, y buscamos el 'enlace_mensual' desde el mismo contenedor padre.\n",
    "        popover_content_fresh = driver.find_element(By.CSS_SELECTOR, css_selector_popover_content)\n",
    "        enlace_mensual = popover_content_fresh.find_element(By.XPATH, xpath_mensual)\n",
    "\n",
    "        datos_sensor['URL_Diaria'] = enlace_diaria.get_attribute(\"href\")\n",
    "        datos_sensor['URL_Mensual'] = enlace_mensual.get_attribute(\"href\")\n",
    "        print(\" [EXTRACCIÓN] OK: Enlaces 'Diaria' y 'Mensual' capturados.\")\n",
    "        \n",
    "    except TimeoutException:\n",
    "        print(f\" [ERROR 1.1] TIMEOUT: El contenido del pop-up no apareció después de {WAIT_TIME} segundos.\")\n",
    "        return datos_sensor\n",
    "    except Exception as e:\n",
    "        print(f\" [ERROR 1.2] EXCEPCIÓN: Fallo al encontrar la CELDA o los enlaces. Tipo: {type(e).__name__}.\")\n",
    "        return datos_sensor\n",
    "\n",
    "    # 3. Extracción de datos con RegEx (Sin cambios)\n",
    "    try:\n",
    "        # Se asume que el ID que buscas es el que aparece como 'Clave' en el resultado final\n",
    "        datos_sensor['Clave'] = str(id_sensor).strip() \n",
    "        \n",
    "        # Las extracciones de Nombre, Latitud y Longitud se mantienen usando el texto del pop-up\n",
    "        nombre_match = re.search(r'<b>Nombre: </b>(.*?)<br>', datos_texto)\n",
    "        latitud_match = re.search(r'<b>Latitud: </b>(.*?)º', datos_texto)\n",
    "        longitud_match = re.search(r'<b>Longitud: </b>(.*?)º', datos_texto)\n",
    "        \n",
    "        if nombre_match:\n",
    "            # En este caso, el nombre de la estación se extrae del texto del pop-up, no del CSV.\n",
    "            datos_sensor['Nombre'] = nombre_match.group(1).strip()\n",
    "        if latitud_match:\n",
    "            datos_sensor['Latitud'] = latitud_match.group(1).strip()\n",
    "        if longitud_match:\n",
    "            datos_sensor['Longitud'] = longitud_match.group(1).strip()\n",
    "        \n",
    "        datos_sensor['Estado'] = 'EXITO'\n",
    "        print(\" [RESULTADO] Extracción de datos exitosa.\")\n",
    "    except Exception as e:\n",
    "        print(f\" [ERROR 1.3] EXCEPCIÓN: Fallo en el procesamiento RegEx. Tipo: {type(e).__name__}.\")\n",
    "        datos_sensor['Estado'] = 'FALLO (RegEx)'\n",
    "        \n",
    "    return datos_sensor\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# --- PARTE 2: PRUEBA DE EJECUCIÓN MASIVA ---\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# LLAMADA CORREGIDA: Pasamos los DataFrames cargados globalmente\n",
    "ID_A_PROCESAR = cargar_ids_a_procesar(ARCHIVO_OPERATIVAS_DF, ARCHIVO_SUSPENDIDAS_DF)\n",
    "\n",
    "# Solo se procede si se cargaron IDs\n",
    "if ID_A_PROCESAR:\n",
    "    try:\n",
    "        # 2.1 Inicialización del driver\n",
    "        print(\" [INICIO] Intentando inicializar Mozilla Firefox (GeckoDriver)...\")\n",
    "        driver = webdriver.Firefox() \n",
    "        driver.get(URL_CONAGUA)\n",
    "        \n",
    "        # 2.2 Configuración inicial (filtros y doble zoom)\n",
    "        print(\" [SETUP] Configurando el mapa (filtros y zoom)...\")\n",
    "        arrow_icon = WebDriverWait(driver, WAIT_TIME).until(EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector_arrow)))\n",
    "        arrow_icon.click()\n",
    "        time.sleep(2)\n",
    "        \n",
    "        for selector in [css_selector_checkbox_operando, css_selector_checkbox_suspendida]:\n",
    "            checkbox = WebDriverWait(driver, WAIT_TIME).until(EC.element_to_be_clickable((By.CSS_SELECTOR, selector)))\n",
    "            if not checkbox.is_selected(): checkbox.click() \n",
    "        time.sleep(1) \n",
    "        \n",
    "        # Doble Zoom In \n",
    "        zoom_in_button = WebDriverWait(driver, WAIT_TIME).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector_zoom_in))\n",
    "        )\n",
    "        zoom_in_button.click()\n",
    "        time.sleep(1) \n",
    "        zoom_in_button.click() # Segundo clic para zoom adicional\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # 2.3 Cerrar Panel\n",
    "        close_button = WebDriverWait(driver, WAIT_TIME).until(EC.element_to_be_clickable((By.CSS_SELECTOR, css_selector_close_panel)))\n",
    "        close_button.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "        # 2.4 Bucle de procesamiento masivo\n",
    "        print(\"\\n--- INICIANDO PROCESAMIENTO MASIVO DE ESTACIONES ---\")\n",
    "        total_ids = len(ID_A_PROCESAR)\n",
    "        \n",
    "        for i, id_sensor in enumerate(ID_A_PROCESAR):\n",
    "            print(f\"\\n[PROGRESO] Estación {i+1} de {total_ids}\")\n",
    "            \n",
    "            datos = extraer_datos_sensor(id_sensor, driver)\n",
    "            resultados_finales.append(datos)\n",
    "            \n",
    "            # Limpiar el pop-up\n",
    "            try:\n",
    "                map_element = driver.find_element(By.ID, \"map\") \n",
    "                ActionChains(driver).move_to_element(map_element).click().perform()\n",
    "                time.sleep(1)\n",
    "            except Exception as e:\n",
    "                print(f\" [ADVERTENCIA] No se pudo limpiar el pop-up. Error: {type(e).__name__}.\")\n",
    "\n",
    "\n",
    "    finally:\n",
    "        # -------------------------------------------------------------------\n",
    "        # --- RESULTADOS FINALES Y ALMACENAMIENTO ---\n",
    "        # -------------------------------------------------------------------\n",
    "        print(\"\\n==============================================\")\n",
    "        print(\"      PROCESAMIENTO FINALIZADO      \")\n",
    "        print(\"==============================================\")\n",
    "        \n",
    "        if resultados_finales:\n",
    "            df_final = pd.DataFrame(resultados_finales)\n",
    "            \n",
    "            # Almacenar los resultados en un CSV\n",
    "            try:\n",
    "                df_final.to_csv(ARCHIVO_SALIDA, index=False, encoding='utf-8') #Guardando resultados\n",
    "                print(f\" [CSV EXPORTADO] Resultados guardados en '{ARCHIVO_SALIDA}'.\")\n",
    "                print(f\"\\nResumen de resultados:\\n{df_final['Estado'].value_counts().to_string()}\")\n",
    "            except Exception as e:\n",
    "                print(f\" [ERROR FATAL] No se pudo guardar el archivo CSV '{ARCHIVO_SALIDA}'. Error: {e}\")\n",
    "        else:\n",
    "            print(\"La extracción falló completamente. No se obtuvieron resultados.\")\n",
    "            \n",
    "        if driver:\n",
    "            print(\"\\nPrueba finalizada. Cierra el navegador manualmente.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n==============================================\")\n",
    "    print(\"      PROCESAMIENTO ABORTADO      \")\n",
    "    print(\"==============================================\")\n",
    "    print(\"No se cargó ningún ID. Por favor, asegúrese de que la ruta de los archivos CSV sea correcta y que contengan la columna 'Name'.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO8Bf6q4uuAejrZY9gPqYrW",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
